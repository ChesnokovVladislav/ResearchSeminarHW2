{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3494804e",
   "metadata": {},
   "source": [
    "# WordCount for Appstore reviews for popular virtual platforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0b762",
   "metadata": {},
   "source": [
    "To parse AppStore reviews, I use app_store_scraper and iteratively collect data form different app reviews in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed4b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: app_store_scraper in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (0.3.5)\r\n",
      "Requirement already satisfied: requests==2.23.0 in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (from app_store_scraper) (2.23.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (from requests==2.23.0->app_store_scraper) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (from requests==2.23.0->app_store_scraper) (1.25.11)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (from requests==2.23.0->app_store_scraper) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/vladislavcesnokov/opt/anaconda3/envs/sparkles/lib/python3.9/site-packages (from requests==2.23.0->app_store_scraper) (2.10)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install app_store_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4db16b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vladislavcesnokov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import all the nessesary packages\n",
    "\n",
    "from app_store_scraper import AppStore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords =stopwords.words('english')\n",
    "\n",
    "#not all default stopwords parameters catch unessesary words in reviews, so I extend this list with other words\n",
    "stopwords.extend(['it’s', 'also', 'would','don’t','i’m', 'i’ve']) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(rc=custom_params, palette = 'pastel')\n",
    "\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74648711",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 00:11:52,013 [INFO] Base - Initialised: AppStore('us', 'telegram-messenger', 686449807)\n",
      "2022-03-28 00:11:52,015 [INFO] Base - Ready to fetch reviews from: https://apps.apple.com/us/app/telegram-messenger/id686449807\n",
      "2022-03-28 00:11:58,227 [INFO] Base - [id:686449807] Fetched 100 reviews (100 fetched in total)\n",
      "2022-03-28 00:12:04,634 [INFO] Base - [id:686449807] Fetched 200 reviews (200 fetched in total)\n",
      "2022-03-28 00:12:07,038 [INFO] Base - Initialised: AppStore('us', 'twitter', 333903271)\n",
      "2022-03-28 00:12:07,039 [INFO] Base - Ready to fetch reviews from: https://apps.apple.com/us/app/twitter/id333903271\n",
      "2022-03-28 00:12:12,041 [INFO] Base - [id:333903271] Fetched 80 reviews (80 fetched in total)\n",
      "2022-03-28 00:12:18,455 [INFO] Base - [id:333903271] Fetched 180 reviews (180 fetched in total)\n",
      "2022-03-28 00:12:19,689 [INFO] Base - [id:333903271] Fetched 200 reviews (200 fetched in total)\n",
      "2022-03-28 00:12:22,064 [INFO] Base - Initialised: AppStore('us', 'whatsapp-messenger', 310633997)\n",
      "2022-03-28 00:12:22,066 [INFO] Base - Ready to fetch reviews from: https://apps.apple.com/us/app/whatsapp-messenger/id310633997\n",
      "2022-03-28 00:12:28,639 [INFO] Base - [id:310633997] Fetched 100 reviews (100 fetched in total)\n",
      "2022-03-28 00:12:34,860 [INFO] Base - [id:310633997] Fetched 200 reviews (200 fetched in total)\n"
     ]
    }
   ],
   "source": [
    "### Set AppStore ID and AppStore app name from appstore link\n",
    "AppStoreDict = {'686449807': 'telegram-messenger', \n",
    "                '333903271': 'twitter', \n",
    "                '310633997': 'whatsapp-messenger', \n",
    "                '389801252': 'instagram',\n",
    "                '284882215': 'facebook',\n",
    "                '414478124': 'wechat',\n",
    "               '874139669': 'signal-private-messenger',\n",
    "               '447188370': 'snapchat',\n",
    "               '429047995': 'pinterest',\n",
    "               '985746746': 'discord-chat-talk-hangout'}\n",
    "\n",
    "### Create dictionary with links and app names for ease of future iterative work\n",
    "LocalAppDict = dict()\n",
    "\n",
    "for key in AppStoreDict:\n",
    "    app = AppStore(country='us', app_name=AppStoreDict[key], app_id = key)\n",
    "    \n",
    "    ###Set the number of reviews\n",
    "    app.review(how_many=200)\n",
    "    \n",
    "    ###Create dataframe\n",
    "    df = pd.DataFrame(np.array(app.reviews),columns=['review'])\n",
    "    df2 = df.join(pd.DataFrame(df.pop('review').tolist()))\n",
    "    \n",
    "    ### Select only review columns\n",
    "    review_only = df2['review']\n",
    "    \n",
    "    ### Set path for data import\n",
    "    name = '/Users/vladislavcesnokov/Desktop/HW2 Data/App Store Review '+AppStoreDict[key]+'.csv'\n",
    "    \n",
    "    ### Save data in a folder\n",
    "    review_only.to_csv(name, header=None,index=False)\n",
    "    LocalAppDict[AppStoreDict[key]] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46553bd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LocalAppDict ### Check local app dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8748c",
   "metadata": {},
   "source": [
    "## Counting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61546c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"WordCount\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext\n",
    "\n",
    "#Remove Punctuation and Transform All Words to Lowercase\n",
    "def lower_clean_str(x):\n",
    "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
    "  lowercased_str = x.lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, '')\n",
    "  return lowercased_str\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for key in LocalAppDict:\n",
    "    path = LocalAppDict[key]\n",
    "    apps_rdd=sc.textFile(path)\n",
    "    apps_rdd = apps_rdd.map(lower_clean_str)\n",
    "    \n",
    "    #Split sentence into list of words\n",
    "    apps_rdd=apps_rdd.flatMap(lambda satir: satir.split(\" \"))\n",
    "    \n",
    "    #Exclude whitespaces\n",
    "    apps_rdd = apps_rdd.filter(lambda x:x!='')\n",
    "    \n",
    "    #Count how many times each word occurs\n",
    "    apps_count=apps_rdd.map(lambda  word:(word,1))\n",
    "    \n",
    "    ##Apply ReduceByKey, rank words and exclude stopwords\n",
    "    apps_count_RBK=apps_count.reduceByKey(lambda x,y:(x+y)).sortByKey()\n",
    "    apps_count_RBK=apps_count_RBK.map(lambda x:(x[1],x[0]))\n",
    "    apps_count_RBK = apps_count_RBK.filter(lambda x: x[1] not in stopwords).sortByKey(False)\n",
    "    deptDF = spark.createDataFrame(apps_count_RBK, schema = ['Count', 'Word'])\n",
    "    pandasDF = deptDF.toPandas()\n",
    "    pandasDF['Flag'] = key\n",
    "    df = pd.concat([df, pandasDF], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Count', ascending = 0)[:10] #See 10 most frequent words in reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efdcfd3",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd3c11",
   "metadata": {},
   "source": [
    "### Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba031c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ''\n",
    "\n",
    "#Build wordcloud for every app\n",
    "for val in df['Word']:\n",
    "    tokens = str(val)\n",
    "    tokens = val.split()\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.title(label='\\n'+ \"Wordcloud for all apps\"+'\\n', fontsize=40, color=\"Black\")\n",
    "plt.show()\n",
    "comment_words = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f7f2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comment_words = ''\n",
    "for app in df['Flag'].unique():\n",
    "    targetdf = df[df['Flag'] == app]\n",
    "    # iterate through the csv file\n",
    "    for val in targetdf['Word']:\n",
    "         \n",
    "        # typecaste each val to string\n",
    "        tokens = str(val)\n",
    "     \n",
    "        # split the value\n",
    "        tokens = val.split()\n",
    "         \n",
    "        # Converts each token into lowercase\n",
    "        for i in range(len(tokens)):\n",
    "            tokens[i] = tokens[i].lower()\n",
    "         \n",
    "        comment_words += \" \".join(tokens)+\" \"\n",
    "     \n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='white',\n",
    "                    stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "     \n",
    "    # plot the WordCloud image                      \n",
    "    plt.figure(figsize = (8, 8), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.title(label='\\n'+ \"Wordcloud for \"+app+'\\n', fontsize=40, color=\"Black\")\n",
    "    plt.show()\n",
    "    comment_words = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98987dd5",
   "metadata": {},
   "source": [
    "### Barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 15 #set the number for top-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3719b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Build barcharts for every app\n",
    "for app in df['Flag'].unique():\n",
    "    targetdf = df[df['Flag'] == app]\n",
    "    targetdf[:num].sort_values(by = 'Count').plot.barh(x = 'Word', \n",
    "                                                y = 'Count', \n",
    "                                                figsize=(7,5), \n",
    "                                                legend = False, \n",
    "                                                title = 'Top-'+str(num)+' most frequent words in '+app+' reviews');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sparkles] *",
   "language": "python",
   "name": "conda-env-sparkles-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
